{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACGANs on MNIST",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNK0gocFplK/O9yHJUDnIwi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohit501/ACGAN-on-MNIST/blob/main/ACGANs_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLxgtsHIN0jf"
      },
      "source": [
        "# Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62_oP5yKcpg0"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow import keras\r\n",
        "from keras.layers import Dense,Conv2D,Reshape,Flatten,Conv2DTranspose,Input,BatchNormalization,LeakyReLU,concatenate,Activation\r\n",
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.datasets import mnist\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W8mgj_0N7cE"
      },
      "source": [
        "## Building a Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpdNj-a0LpAb"
      },
      "source": [
        "def Generator(inputs,image_size,activation = 'sigmoid',labels = None,codes = None):\r\n",
        "    image_resize = image_size//4\r\n",
        "    kernel_size = 5\r\n",
        "    layer_filters = [128.64,32,1]\r\n",
        "    if labels is not None:\r\n",
        "       if codes is None:\r\n",
        "          inputs = [inputs,labels]\r\n",
        "       else:\r\n",
        "         inputs = [inputs,labels]+codes\r\n",
        "       x = concatenate(inputs,axis=1)\r\n",
        "    elif codes is not None:\r\n",
        "         inputs = [inputs,code]\r\n",
        "         x = concatenate(inputs,axis = 1)\r\n",
        "    else:\r\n",
        "         x = inputs\r\n",
        "    x = Dense(image_resize*image_resize*128)(x)\r\n",
        "    x = Reshape((image_resize,image_resize,128))(x)\r\n",
        "    for filter in layer_filters:\r\n",
        "        if filter > layer_filters[2]:\r\n",
        "           strides = 2\r\n",
        "        else:\r\n",
        "           strides = 1\r\n",
        "        x = BatchNormalization()(x)\r\n",
        "        x = Activation('relu')(x)\r\n",
        "        x = Conv2DTranspose(filters = filter,kernel_size=kernel_size,strides=strides,padding='same')(x)\r\n",
        "    if activation is not None:\r\n",
        "       x = Activation('sigmoid')(x)\r\n",
        "    generator = Model(inputs,x,name = 'generator')\r\n",
        "    return generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bep9egVxOCcK"
      },
      "source": [
        "## Building a Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AflJ6euNzKC"
      },
      "source": [
        "def Discriminator(inputs,activation = 'sigmoid',num_labels = None,num_codes = None):\r\n",
        "    kernel_size = 5\r\n",
        "    layer_filters = [32,64,128,256]\r\n",
        "    x = inputs\r\n",
        "    for filter in layer_filters:\r\n",
        "        if filter == layer_filters[-1]:\r\n",
        "          strides = 1\r\n",
        "        else: \r\n",
        "          strides = 2\r\n",
        "        x = LeakyReLU(alpha = 0.2)(x)\r\n",
        "        x = Conv2D(filters = filter,strides=strides,kernel_size=kernel_size,padding='same')(x)\r\n",
        "    x = Flatten()(x)\r\n",
        "    outputs = Dense(1)(x)\r\n",
        "    if activation  is not None:\r\n",
        "       print(activation)\r\n",
        "       outputs = Activation(activation)(outputs)\r\n",
        "    if num_labels:\r\n",
        "      layer = Dense(layer_filters[-2])(x)\r\n",
        "      labels = Dense(num_labels)(layer)\r\n",
        "      labels= Activation('softmax',name = 'label')(labels)\r\n",
        "      if num_codes is None:\r\n",
        "        outputs = [outputs,labels]\r\n",
        "      else:\r\n",
        "        code1 = Dense(1)(layer)\r\n",
        "        code1 = Activation('sigmoid')(code1)\r\n",
        "        code2 = Dense(1)(layer)\r\n",
        "        code2 = Activation('sigmoid')(code2)\r\n",
        "        outputs = [outputs,labels,code1,code2]\r\n",
        "    elif num_codes is not None:\r\n",
        "        z0_recon = Dense(num_codes)(x)\r\n",
        "        z0_recon = Activation('')(z0_recon)\r\n",
        "        outputs = [outputs,z0_recon]\r\n",
        "    discriminator = Model(inputs,outputs,name = 'Discriminator')\r\n",
        "    return discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9ceni993Lh"
      },
      "source": [
        "# Building a Train Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEei72Jv91CP"
      },
      "source": [
        "def train(models,data,params):\r\n",
        "    generator,discriminator,adversarial = models\r\n",
        "    x_train,y_train = data\r\n",
        "    batch_size, latent_size, train_steps, num_labels, model_name = params\r\n",
        "    save_interval = 500\r\n",
        "    noise_input = np.random.uniform(-1.0,1.0,size = [16,latent_size])\r\n",
        "    noise_label = np.eye(num_labels)[np.arange(0,16)% num_labels]\r\n",
        "    train_size = x_train.shape[0]\r\n",
        "    print(model_name,'Labels for generated images:',np.argmax(noise_label,axis=1))\r\n",
        "    for i in range (train_steps):\r\n",
        "        rand_indexes = np.random.randint(0,train_size,size = batch_size)\r\n",
        "        real_images = x_train[rand_indexes]\r\n",
        "        real_labels = y_train[rand_indexes]\r\n",
        "        noise = np.random.uniform(-1.0,1.0,size=[batch_size,latent_size])\r\n",
        "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,batch_size)]\r\n",
        "        fake_images = generator.predict([noise,fake_labels])\r\n",
        "        x = np.concatenate((real_images,fake_images))\r\n",
        "        labels = np.concatenate((real_labels,fake_labels))\r\n",
        "        y = np.ones([2*batch_size,1])\r\n",
        "        y[batch_size:,:] = 0 \r\n",
        "        metrics = discriminator.train_on_batch(x,[y,labels])\r\n",
        "        fmt = \"%d [discriminator loss: %f , src loss: %f, lblloss: %f, srcacc: %f, lbl acc: %f]\"\r\n",
        "        log = fmt % (i,metrics[0],metrics[1],metrics[2],metrics[3],metrics[4])\r\n",
        "       \r\n",
        "        noise = np.random.uniform(-1.0,1.0,size=[batch_size,latent_size])\r\n",
        "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,batch_size)]\r\n",
        "        y = np.ones([batch_size,1])\r\n",
        "        metrics = adversarial.train_on_batch([noise,fake_labels],[y,fake_labels])\r\n",
        "        fmt = \"%s [adversarial loss: %f, srcloss: %f,lblloss: %f,srcacc: %f,lblacc: %f]\"\r\n",
        "        log = fmt % (log,metrics[0],metrics[1],metrics[2],metrics[3],metrics[4])\r\n",
        "        print(log)\r\n",
        "        \r\n",
        "        if (i+1) % save_interval == 0:\r\n",
        "            plot_images(generator,noise_input,noise_label,model_name = model_name)\r\n",
        "    generator.save(model_name + \".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOB0v4SqDquT"
      },
      "source": [
        "## Building a PLot Image Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQL8CQ6h9jLU"
      },
      "source": [
        "def plot_images(generator,noise_input,noise_label,show=False,step=0,model_name=\"gan\"):\r\n",
        "    os.makedirs(model_name, exist_ok=True)\r\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\r\n",
        "    images = generator.predict([noise_input,noise_label])\r\n",
        "    plt.figure(figsize=(2, 2))\r\n",
        "    num_images = images.shape[0]\r\n",
        "    image_size = images.shape[1]\r\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\r\n",
        "    for i in range(num_images):\r\n",
        "        plt.subplot(rows, rows, i + 1)\r\n",
        "        image = np.reshape(images[i], [image_size, image_size])\r\n",
        "        plt.imshow(image, cmap='gray')\r\n",
        "        plt.axis('off')\r\n",
        "        \r\n",
        "    plt.savefig(filename)\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTvtS-3NDwIc"
      },
      "source": [
        "# Building  Adversarial Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTa0S9-pQglv"
      },
      "source": [
        "def build_and_train_models():\r\n",
        "    (x_train, y_train), (_, _) = mnist.load_data()\r\n",
        "    image_size = x_train.shape[1]\r\n",
        "    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\r\n",
        "    x_train = x_train.astype('float32') / 255\r\n",
        "    num_labels = len(np.unique(y_train))\r\n",
        "    y_train = to_categorical(y_train)\r\n",
        "    model_name = \"acgan_mnist\"\r\n",
        "    latent_size = 100\r\n",
        "    batch_size = 64\r\n",
        "    train_steps = 40000\r\n",
        "    lr = 2e-4\r\n",
        "    decay = 6e-8\r\n",
        "    input_shape = (image_size, image_size, 1)\r\n",
        "    label_shape = (num_labels, )\r\n",
        "    inputs = Input(shape=input_shape,name='discriminator_input')\r\n",
        "    discriminator = Discriminator(inputs, num_labels=num_labels)\r\n",
        "    optimizer = RMSprop(lr=lr, decay=decay)\r\n",
        "    loss = ['binary_crossentropy', 'categorical_crossentropy']\r\n",
        "    discriminator.compile(loss=loss,optimizer=optimizer,metrics=['accuracy'])\r\n",
        "    discriminator.summary()\r\n",
        "\r\n",
        "    \r\n",
        "    input_shape = (latent_size, )\r\n",
        "    inputs = Input(shape=input_shape, name='z_input')\r\n",
        "    labels = Input(shape=label_shape, name='labels')\r\n",
        "\r\n",
        "    generator = Generator(inputs,image_size,labels=labels)\r\n",
        "    generator.summary()\r\n",
        "    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\r\n",
        "    discriminator.trainable = False\r\n",
        "    adversarial = Model([inputs, labels],discriminator(generator([inputs, labels])),name=model_name)\r\n",
        "    adversarial.compile(loss=loss,optimizer=optimizer,metrics=['accuracy'])\r\n",
        "    adversarial.summary()\r\n",
        "    models = (generator, discriminator, adversarial)\r\n",
        "    data = (x_train, y_train)\r\n",
        "    params = (batch_size, latent_size,train_steps, num_labels, model_name)\r\n",
        "    train(models, data, params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sf3XBNWGnnH"
      },
      "source": [
        "build_and_train_models()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}